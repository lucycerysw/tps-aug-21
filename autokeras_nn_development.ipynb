{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f6b2a9-9f3b-45f0-8f28-3657255810cb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90672260-a6ef-455d-bff8-83e26499125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from warnings import filterwarnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_path = r'D:/KaggleTabular/August/train.csv'\n",
    "test_path = r'D:/KaggleTabular/August/test.csv'\n",
    "submission_path = r'D:/KaggleTabular/August/sample_submission.csv'\n",
    "\n",
    "rs = 69420\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba96f72-86f3-4bb3-a9a0-5f146bfbc213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002350</td>\n",
       "      <td>59</td>\n",
       "      <td>0.766739</td>\n",
       "      <td>-1.350460</td>\n",
       "      <td>42.2727</td>\n",
       "      <td>16.68570</td>\n",
       "      <td>30.3599</td>\n",
       "      <td>1.267300</td>\n",
       "      <td>0.392007</td>\n",
       "      <td>1.09101</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.43990</td>\n",
       "      <td>26.854000</td>\n",
       "      <td>1.45751</td>\n",
       "      <td>0.696161</td>\n",
       "      <td>0.941764</td>\n",
       "      <td>1.828470</td>\n",
       "      <td>0.924090</td>\n",
       "      <td>2.29658</td>\n",
       "      <td>10.48980</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.784462</td>\n",
       "      <td>145</td>\n",
       "      <td>-0.463845</td>\n",
       "      <td>-0.530421</td>\n",
       "      <td>27324.9000</td>\n",
       "      <td>3.47545</td>\n",
       "      <td>160.4980</td>\n",
       "      <td>0.828007</td>\n",
       "      <td>3.735860</td>\n",
       "      <td>1.28138</td>\n",
       "      <td>...</td>\n",
       "      <td>-184.13200</td>\n",
       "      <td>7.901370</td>\n",
       "      <td>1.70644</td>\n",
       "      <td>-0.494699</td>\n",
       "      <td>-2.058300</td>\n",
       "      <td>0.819184</td>\n",
       "      <td>0.439152</td>\n",
       "      <td>2.36470</td>\n",
       "      <td>1.14383</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.317816</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.432571</td>\n",
       "      <td>-0.382644</td>\n",
       "      <td>1383.2600</td>\n",
       "      <td>19.71290</td>\n",
       "      <td>31.1026</td>\n",
       "      <td>-0.515354</td>\n",
       "      <td>34.430800</td>\n",
       "      <td>1.24210</td>\n",
       "      <td>...</td>\n",
       "      <td>7.43721</td>\n",
       "      <td>37.218100</td>\n",
       "      <td>3.25339</td>\n",
       "      <td>0.337934</td>\n",
       "      <td>0.615037</td>\n",
       "      <td>2.216760</td>\n",
       "      <td>0.745268</td>\n",
       "      <td>1.69679</td>\n",
       "      <td>12.30550</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210753</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.616454</td>\n",
       "      <td>0.946362</td>\n",
       "      <td>-119.2530</td>\n",
       "      <td>4.08235</td>\n",
       "      <td>185.2570</td>\n",
       "      <td>1.383310</td>\n",
       "      <td>-47.521400</td>\n",
       "      <td>1.09130</td>\n",
       "      <td>...</td>\n",
       "      <td>9.66778</td>\n",
       "      <td>0.626942</td>\n",
       "      <td>1.49425</td>\n",
       "      <td>0.517513</td>\n",
       "      <td>-10.222100</td>\n",
       "      <td>2.627310</td>\n",
       "      <td>0.617270</td>\n",
       "      <td>1.45645</td>\n",
       "      <td>10.02880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.439671</td>\n",
       "      <td>20</td>\n",
       "      <td>0.968126</td>\n",
       "      <td>-0.092546</td>\n",
       "      <td>74.3020</td>\n",
       "      <td>12.30650</td>\n",
       "      <td>72.1860</td>\n",
       "      <td>-0.233964</td>\n",
       "      <td>24.399100</td>\n",
       "      <td>1.10151</td>\n",
       "      <td>...</td>\n",
       "      <td>290.65700</td>\n",
       "      <td>15.604300</td>\n",
       "      <td>1.73557</td>\n",
       "      <td>-0.476668</td>\n",
       "      <td>1.390190</td>\n",
       "      <td>2.195740</td>\n",
       "      <td>0.826987</td>\n",
       "      <td>1.78485</td>\n",
       "      <td>7.07197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f0   f1        f2        f3          f4        f5        f6  \\\n",
       "id                                                                      \n",
       "0  -0.002350   59  0.766739 -1.350460     42.2727  16.68570   30.3599   \n",
       "1   0.784462  145 -0.463845 -0.530421  27324.9000   3.47545  160.4980   \n",
       "2   0.317816   19 -0.432571 -0.382644   1383.2600  19.71290   31.1026   \n",
       "3   0.210753   17 -0.616454  0.946362   -119.2530   4.08235  185.2570   \n",
       "4   0.439671   20  0.968126 -0.092546     74.3020  12.30650   72.1860   \n",
       "\n",
       "          f7         f8       f9  ...        f91        f92      f93  \\\n",
       "id                                ...                                  \n",
       "0   1.267300   0.392007  1.09101  ...  -42.43990  26.854000  1.45751   \n",
       "1   0.828007   3.735860  1.28138  ... -184.13200   7.901370  1.70644   \n",
       "2  -0.515354  34.430800  1.24210  ...    7.43721  37.218100  3.25339   \n",
       "3   1.383310 -47.521400  1.09130  ...    9.66778   0.626942  1.49425   \n",
       "4  -0.233964  24.399100  1.10151  ...  290.65700  15.604300  1.73557   \n",
       "\n",
       "         f94        f95       f96       f97      f98       f99  loss  \n",
       "id                                                                    \n",
       "0   0.696161   0.941764  1.828470  0.924090  2.29658  10.48980    15  \n",
       "1  -0.494699  -2.058300  0.819184  0.439152  2.36470   1.14383     3  \n",
       "2   0.337934   0.615037  2.216760  0.745268  1.69679  12.30550     6  \n",
       "3   0.517513 -10.222100  2.627310  0.617270  1.45645  10.02880     2  \n",
       "4  -0.476668   1.390190  2.195740  0.826987  1.78485   7.07197     1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(train_path, index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727f1292-e406-48ee-b725-c9f33467db7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250000, 100), (250000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.iloc[:, :-1].values\n",
    "y = train.iloc[:, -1].values\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15bee5b6-c564-44d1-8cde-12027372ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a278cca-ec59-4479-961b-d868889d6286",
   "metadata": {},
   "source": [
    "# AutoKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23f8034-98fb-47bc-8562-c95e63ee09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338a5e11-7512-42e4-b0c6-5b5a1cf1fc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\tps-aug-21\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\tps-aug-21\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "clf = ak.StructuredDataRegressor(overwrite=False,\n",
    "                                 project_name='tps-aug-21',\n",
    "                                 metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "                                 tuner='bayesian',\n",
    "                                 max_trials=100,\n",
    "                                 objective=\"val_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84b5f2c7-8ef3-4b4d-8dab-b90c82c3a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5087e86-5732-452a-bca2-055d42f09388",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99 Complete [00h 06m 01s]\n",
      "val_loss: 62.615787506103516\n",
      "\n",
      "Best val_loss So Far: 61.98082733154297\n",
      "Total elapsed time: 03h 19m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/50\n",
      "489/489 [==============================] - 8s 14ms/step - loss: 84.0498 - root_mean_squared_error: 9.0160\n",
      "Epoch 2/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 68.7547 - root_mean_squared_error: 8.2918\n",
      "Epoch 3/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 67.1755 - root_mean_squared_error: 8.1961\n",
      "Epoch 4/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 66.4001 - root_mean_squared_error: 8.1486\n",
      "Epoch 5/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 65.6234 - root_mean_squared_error: 8.1008\n",
      "Epoch 6/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 64.9991 - root_mean_squared_error: 8.0622\n",
      "Epoch 7/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 64.4652 - root_mean_squared_error: 8.0290\n",
      "Epoch 8/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 64.0650 - root_mean_squared_error: 8.0041\n",
      "Epoch 9/50\n",
      "489/489 [==============================] - 7s 15ms/step - loss: 63.7500 - root_mean_squared_error: 7.9844\n",
      "Epoch 10/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 63.4470 - root_mean_squared_error: 7.9654\n",
      "Epoch 11/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 63.1253 - root_mean_squared_error: 7.9451\n",
      "Epoch 12/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 63.0016 - root_mean_squared_error: 7.9374\n",
      "Epoch 13/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 62.7362 - root_mean_squared_error: 7.9206\n",
      "Epoch 14/50\n",
      "489/489 [==============================] - 7s 15ms/step - loss: 62.5030 - root_mean_squared_error: 7.9059\n",
      "Epoch 15/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 62.2694 - root_mean_squared_error: 7.8911\n",
      "Epoch 16/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 62.1066 - root_mean_squared_error: 7.8808\n",
      "Epoch 17/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 61.9797 - root_mean_squared_error: 7.8727\n",
      "Epoch 18/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 61.8673 - root_mean_squared_error: 7.8656\n",
      "Epoch 19/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 61.7341 - root_mean_squared_error: 7.8571\n",
      "Epoch 20/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 61.6259 - root_mean_squared_error: 7.8502\n",
      "Epoch 21/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 61.4685 - root_mean_squared_error: 7.8402\n",
      "Epoch 22/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 61.3739 - root_mean_squared_error: 7.8341\n",
      "Epoch 23/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 61.2621 - root_mean_squared_error: 7.8270\n",
      "Epoch 24/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 61.2062 - root_mean_squared_error: 7.8234\n",
      "Epoch 25/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 61.1102 - root_mean_squared_error: 7.8173\n",
      "Epoch 26/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 61.0768 - root_mean_squared_error: 7.8152\n",
      "Epoch 27/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.9397 - root_mean_squared_error: 7.8064\n",
      "Epoch 28/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.9376 - root_mean_squared_error: 7.8063\n",
      "Epoch 29/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.8669 - root_mean_squared_error: 7.8017\n",
      "Epoch 30/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.8248 - root_mean_squared_error: 7.7990\n",
      "Epoch 31/50\n",
      "489/489 [==============================] - 7s 15ms/step - loss: 60.7547 - root_mean_squared_error: 7.7945\n",
      "Epoch 32/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.7249 - root_mean_squared_error: 7.7926\n",
      "Epoch 33/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.6450 - root_mean_squared_error: 7.7875\n",
      "Epoch 34/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.5873 - root_mean_squared_error: 7.7838\n",
      "Epoch 35/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.5131 - root_mean_squared_error: 7.7790\n",
      "Epoch 36/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.5336 - root_mean_squared_error: 7.7803\n",
      "Epoch 37/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.4697 - root_mean_squared_error: 7.7762\n",
      "Epoch 38/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.3302 - root_mean_squared_error: 7.7673\n",
      "Epoch 39/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.3572 - root_mean_squared_error: 7.7690\n",
      "Epoch 40/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.2654 - root_mean_squared_error: 7.7631\n",
      "Epoch 41/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.1864 - root_mean_squared_error: 7.7580\n",
      "Epoch 42/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.2144 - root_mean_squared_error: 7.7598\n",
      "Epoch 43/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.1198 - root_mean_squared_error: 7.7537\n",
      "Epoch 44/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.0466 - root_mean_squared_error: 7.7490\n",
      "Epoch 45/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 60.0428 - root_mean_squared_error: 7.7487\n",
      "Epoch 46/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 59.9660 - root_mean_squared_error: 7.7438\n",
      "Epoch 47/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 59.8753 - root_mean_squared_error: 7.7379\n",
      "Epoch 48/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 59.8611 - root_mean_squared_error: 7.7370\n",
      "Epoch 49/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 59.7764 - root_mean_squared_error: 7.7315\n",
      "Epoch 50/50\n",
      "489/489 [==============================] - 7s 14ms/step - loss: 59.7159 - root_mean_squared_error: 7.7276\n",
      "INFO:tensorflow:Assets written to: .\\tps-aug-21\\best_model\\assets\n",
      "Wall time: 3h 26min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X, y,\n",
    "        validation_split=0.15,\n",
    "        batch_size=512,\n",
    "        epochs=50,\n",
    "        shuffle=True,\n",
    "        callbacks=[es],\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afafc5af-f3ad-45b0-a538-6b0141ac2736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "multi_category_encoding (Mul (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 100)               201       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "regression_head_1 (Dense)    (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 62,250\n",
      "Trainable params: 60,993\n",
      "Non-trainable params: 1,257\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984d2fb-d2e7-4513-be0f-d12da7d5dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"autokeras_tps_aug\", save_format=\"tf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
